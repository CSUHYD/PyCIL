{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ac6f8b-ccc2-4554-b2cb-b7f1ffa5bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "from trainer import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f78f10f2-7ef9-41ff-b8c6-480a832cffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--config CONFIG]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/cdi/.local/share/jupyter/runtime/kernel-1a9f06cd-a4cc-4921-89df-98de2b161eb5.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdi/anaconda3/envs/cl/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args = setup_parser().parse_args()\n",
    "    param = load_json(args.config)\n",
    "    args = vars(args)  # Converting argparse Namespace to a dict.\n",
    "    args.update(param)  # Add parameters from json\n",
    "\n",
    "    train(args)\n",
    "\n",
    "\n",
    "def load_json(settings_path):\n",
    "    with open(settings_path) as data_file:\n",
    "        param = json.load(data_file)\n",
    "\n",
    "    return param\n",
    "\n",
    "\n",
    "def setup_parser():\n",
    "    parser = argparse.ArgumentParser(description='Reproduce of multiple continual learning algorthms.')\n",
    "    parser.add_argument('--config', type=str, default='./exps/finetune.json',\n",
    "                        help='Json file of settings.')\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe30ed8-0c87-49b1-92b9-693df7e1fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = setup_parser().parse_args([])\n",
    "param = load_json(args.config)\n",
    "args = vars(args)  # Converting argparse Namespace to a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff7fe37-2ebe-4ab6-ae4e-12212269f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.update(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f82ab354-048f-4c57-b7d0-7e15a6f35d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': './exps/finetune.json',\n",
       " 'prefix': 'reproduce',\n",
       " 'dataset': 'cifar100',\n",
       " 'memory_size': 2000,\n",
       " 'memory_per_class': 20,\n",
       " 'fixed_memory': False,\n",
       " 'shuffle': True,\n",
       " 'init_cls': 10,\n",
       " 'increment': 10,\n",
       " 'model_name': 'finetune',\n",
       " 'convnet_type': 'resnet32',\n",
       " 'device': ['0', '1', '2', '3'],\n",
       " 'seed': [1993]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e670f95-efa8-4f99-933f-a9aaabf01797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': './exps/finetune.json',\n",
       " 'prefix': 'reproduce',\n",
       " 'dataset': 'cifar100',\n",
       " 'memory_size': 2000,\n",
       " 'memory_per_class': 20,\n",
       " 'fixed_memory': False,\n",
       " 'shuffle': True,\n",
       " 'init_cls': 10,\n",
       " 'increment': 10,\n",
       " 'model_name': 'finetune',\n",
       " 'convnet_type': 'resnet32',\n",
       " 'device': ['0', '1', '2', '3'],\n",
       " 'seed': [1993]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97281c4b-bc49-40e6-b1a5-b96310264adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 3, 3, 2, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [3,1,2,0,0,1,2]\n",
    "order = [3,2,1,0]\n",
    "\n",
    "np.array(list(map(lambda x: order.index(x), y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f1351d-4cf8-46d7-a24a-0581803acc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order.index(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94f33001-ce0b-45e7-b33c-b602f805aa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b224e0dc-d16c-41dd-a631-048328ed9a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(y):  <class 'torch.Tensor'>\n",
      "y.grad:  None\n",
      "y_grad[0]:  tensor([[1.0000, 1.5000],\n",
      "        [2.0000, 2.5000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12876/2049154631.py:13: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/build/aten/src/ATen/core/TensorBody.h:480.)\n",
      "  print(\"y.grad: \", y.grad)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def grad_hook(grad):\n",
    "    y_grad.append(grad)\n",
    "    \n",
    "y_grad = list()\n",
    "x = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True)\n",
    "y = x + 1\n",
    "y.register_hook(grad_hook)\n",
    "z = torch.mean(y*y)\n",
    "z.backward()\n",
    "print(\"type(y): \", type(y))\n",
    "print(\"y.grad: \", y.grad)\n",
    "print(\"y_grad[0]: \", y_grad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d5e36d5-1442-4bdf-8189-ce69d1df2669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.grad:  None\n",
      "y_grad[0]:  tensor([0.2500, 0.2500, 0.2500, 0.2500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12876/2715971943.py:10: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/build/aten/src/ATen/core/TensorBody.h:480.)\n",
      "  print(\"y.grad: \", y.grad)\n"
     ]
    }
   ],
   "source": [
    "y_grad = list()\n",
    "def grad_hook(grad):\n",
    "    y_grad.append(grad)\n",
    "    \n",
    "x = torch.tensor([2., 2., 2., 2.], requires_grad=True)\n",
    "y = torch.pow(x, 2)\n",
    "z = torch.mean(y)\n",
    "h = y.register_hook(grad_hook)\n",
    "z.backward()\n",
    "print(\"y.grad: \", y.grad)\n",
    "print(\"y_grad[0]: \", y_grad[0])\n",
    "h.remove()    # removes the hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e37a6af-3fb6-476e-913a-dbfd529dfb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl",
   "language": "python",
   "name": "cl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
